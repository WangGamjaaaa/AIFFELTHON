{"cells":[{"cell_type":"markdown","metadata":{"id":"EeCohpL5LNAH"},"source":["# Baseline Model\n"," - Oriented_rcnn_r50_fpn_1x_dota_le90"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtQIsLscLLzG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664153927920,"user_tz":-540,"elapsed":6,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}},"outputId":"342d72b2-cea1-4093-a9fe-570667cad1c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"]}],"source":["# Check nvcc version\n","!nvcc -V\n","# Check GCC version\n","!gcc --version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8492,"status":"ok","timestamp":1664153936409,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"qmpnzQ_QLu23","outputId":"3cbe78e7-0e37-4663-f1fc-9c31378ccfff"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.8 MB 8.2 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 78.8 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 94.6 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 68.1 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 93.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 53.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 92.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 95.8 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 98.2 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 80.5 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 93.8 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install wandb -qU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":485,"status":"ok","timestamp":1664153936891,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"BMA6D5GYLv7x","outputId":"a3a93f50-7094-41ef-cf93-4640bbf17e9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4095,"status":"ok","timestamp":1664153940982,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"O9_Ys93rLwz-","outputId":"97c10cea-8265-4a24-989d-d684d7db351a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openmim\n","  Downloading openmim-0.3.2-py2.py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 4.0 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Collecting rich\n","  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 18.2 MB/s \n","\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.7/dist-packages (from openmim) (7.1.2)\n","Collecting model-index\n","  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n","Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.7/dist-packages (from openmim) (21.1.3)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from openmim) (0.8.10)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openmim) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from openmim) (1.3.5)\n","Collecting ordered-set\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (3.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (6.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown->model-index->openmim) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2022.2.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->openmim) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2022.6.15)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->openmim) (2.6.1)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 8.2 MB/s \n","\u001b[?25hInstalling collected packages: ordered-set, commonmark, rich, model-index, colorama, openmim\n","Successfully installed colorama-0.4.5 commonmark-0.9.1 model-index-0.1.11 openmim-0.3.2 ordered-set-4.1.0 rich-12.5.1\n"]}],"source":["!pip install openmim"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15550,"status":"ok","timestamp":1664153956530,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"xgeb2E1VLx4-","outputId":"290dee36-6126-48b7-a9ff-33d29fb11a7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n","Collecting mmcv-full===1.6.0\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/mmcv_full-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (40.1 MB)\n","\u001b[K     |████████████████████████████████| 40.1 MB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full===1.6.0) (6.0)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full===1.6.0) (4.6.0.66)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full===1.6.0) (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full===1.6.0) (1.21.6)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full===1.6.0) (7.1.2)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full===1.6.0) (3.0.9)\n","Installing collected packages: yapf, addict, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.6.0 yapf-0.32.0\n"]}],"source":["!mim install mmcv-full===1.6.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6998,"status":"ok","timestamp":1664153963526,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"IMb239GTLzkO","outputId":"8c60f0b8-8db8-4118-aeae-a1287664b36a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n","Collecting mmdet\n","  Downloading mmdet-2.25.2-py3-none-any.whl (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 7.0 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet) (3.2.2)\n","Collecting terminaltables\n","  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet) (2.0.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.15.0)\n","Requirement already satisfied: mmcv-full>=1.3.17 in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.6.0)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet) (4.6.0.66)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet) (7.1.2)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet) (0.32.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet) (21.3)\n","Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet) (2.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full>=1.3.17->mmdet) (6.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmdet) (4.1.1)\n","Installing collected packages: terminaltables, mmdet\n","Successfully installed mmdet-2.25.2 terminaltables-3.1.10\n"]}],"source":["!mim install mmdet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5469,"status":"ok","timestamp":1664153968992,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"Sv0Lim2Qxlvd","outputId":"1347f28b-50c9-4ce5-8fc3-0b56bdd69fc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n","Collecting mmengine\n","  Downloading mmengine-0.1.0-py3-none-any.whl (280 kB)\n","\u001b[K     |████████████████████████████████| 280 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmengine) (2.4.0)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmengine) (4.6.0.66)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from mmengine) (1.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmengine) (1.21.6)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmengine) (0.32.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmengine) (3.2.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmengine) (6.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine) (1.4.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmengine) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmengine) (1.15.0)\n","Installing collected packages: mmengine\n","Successfully installed mmengine-0.1.0\n"]}],"source":["!mim install mmengine"]},{"cell_type":"markdown","metadata":{"id":"R6gEzD-jL1U_"},"source":["# Git clone part\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2154,"status":"ok","timestamp":1664153971143,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"_aCALWIoL03f","outputId":"74e7d756-1045-4c4d-e870-29285cd9ac69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mmrotate'...\n","remote: Enumerating objects: 2242, done.\u001b[K\n","remote: Counting objects: 100% (77/77), done.\u001b[K\n","remote: Compressing objects: 100% (60/60), done.\u001b[K\n","remote: Total 2242 (delta 30), reused 48 (delta 17), pack-reused 2165\u001b[K\n","Receiving objects: 100% (2242/2242), 21.59 MiB | 25.56 MiB/s, done.\n","Resolving deltas: 100% (1278/1278), done.\n"]}],"source":["!git clone https://github.com/open-mmlab/mmrotate.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1664153971144,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"h-WtVQnaL4PI","outputId":"785dae45-d25c-4e77-b3b8-ca98cada4bbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmrotate\n"]}],"source":["%cd mmrotate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1664153971144,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"okCQ-lnIL5Bh","outputId":"2bceed96-892b-48d4-a731-601982779c8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmrotate\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2906,"status":"ok","timestamp":1664153974047,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"VB73NC53L53A","outputId":"59607f40-81e6-4a5b-ec5b-b35f1a5334a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 2)) (0.29.32)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 3)) (1.21.6)\n"]}],"source":["!pip install -r requirements/build.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4951,"status":"ok","timestamp":1664153978996,"user":{"displayName":"윤혜연","userId":"13048533309979940862"},"user_tz":-540},"id":"8JEfxdtiL7MG","outputId":"4178881c-4278-4edb-9fe0-f29e47e39533"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/mmrotate\n","Collecting e2cnn\n","  Downloading e2cnn-0.2.2-py3-none-any.whl (225 kB)\n","\u001b[K     |████████████████████████████████| 225 kB 8.9 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmrotate==0.3.2) (3.2.2)\n","Requirement already satisfied: mmcv-full in /usr/local/lib/python3.7/dist-packages (from mmrotate==0.3.2) (1.6.0)\n","Requirement already satisfied: mmdet in /usr/local/lib/python3.7/dist-packages (from mmrotate==0.3.2) (2.25.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmrotate==0.3.2) (1.21.6)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmrotate==0.3.2) (2.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmrotate==0.3.2) (1.15.0)\n","Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from mmrotate==0.3.2) (3.1.10)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from mmrotate==0.3.2) (1.12.1+cu113)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from e2cnn->mmrotate==0.3.2) (1.7.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from e2cnn->mmrotate==0.3.2) (1.7.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmrotate==0.3.2) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmrotate==0.3.2) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmrotate==0.3.2) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmrotate==0.3.2) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmrotate==0.3.2) (4.1.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full->mmrotate==0.3.2) (7.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full->mmrotate==0.3.2) (21.3)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv-full->mmrotate==0.3.2) (0.32.0)\n","Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full->mmrotate==0.3.2) (2.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full->mmrotate==0.3.2) (6.0)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full->mmrotate==0.3.2) (4.6.0.66)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->e2cnn->mmrotate==0.3.2) (1.2.1)\n","Installing collected packages: e2cnn, mmrotate\n","  Running setup.py develop for mmrotate\n","Successfully installed e2cnn-0.2.2 mmrotate-0.3.2\n"]}],"source":["!pip install -e ."]},{"cell_type":"markdown","metadata":{"id":"NstJxSVnL-8_"},"source":["# Oriented_rcnn download"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"05wrFJ15L-AY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664154000672,"user_tz":-540,"elapsed":21682,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}},"outputId":"0879b88e-d0ff-433b-d97d-10068a1689a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["processing oriented_rcnn_r50_fpn_1x_dota_le90...\n","\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 MiB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[32mSuccessfully downloaded oriented_rcnn_r50_fpn_1x_dota_le90-6d2b2ce0.pth to /content/mmrotate\u001b[0m\n","\u001b[32mSuccessfully dumped oriented_rcnn_r50_fpn_1x_dota_le90.py to /content/mmrotate\u001b[0m\n"]}],"source":["!mim download mmrotate --config oriented_rcnn_r50_fpn_1x_dota_le90 --dest ."]},{"cell_type":"markdown","metadata":{"id":"fg6gN-RtMGiQ"},"source":["#Google Drive mount"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"earyV5JXMGC2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664154022077,"user_tz":-540,"elapsed":21415,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}},"outputId":"22156fae-cbc8-4cf2-a9bd-acfc04d97375"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXLIFVBCMj_-","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1664154027456,"user_tz":-540,"elapsed":5381,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}},"outputId":"b440826c-c518-4259-8c03-d156a051b167"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":15}],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O3y0bP28MLdm"},"outputs":[],"source":["import os\n","from zipfile import ZipFile\n","import time\n","\n","# unzip dataset \n","def extract_zip(zip_path,output_path):\n","  \n","  \"\"\"\n","  Extract .zip File\n","  Args\n","          - zip_path(str) : The path of zip file  \n","  \"\"\"\n","  os.makedirs(output_path, exist_ok=True)\n","  \n","  with ZipFile(zip_path) as zip:\n","      start_time = time.time()\n","      zip.extractall(output_path) \n","      print\n","      print(zip_path,'Unzip Complete')\n","      print(zip_path,\" Unzip Time: {:.4f}sec\".format((time.time() - start_time)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmXkaDIXNP-v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664154609101,"user_tz":-540,"elapsed":581647,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}},"outputId":"bcdc65a3-9afb-4ffd-c110-f6444f3b4f88"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/train_images(sub_all_type).zip Unzip Complete\n","/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/train_images(sub_all_type).zip  Unzip Time: 577.3041sec\n","/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/train_labelTxt_main.zip Unzip Complete\n","/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/train_labelTxt_main.zip  Unzip Time: 1.4315sec\n"]}],"source":["# train\n","dataset_path = '/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/'\n","\n","train_img_path = os.path.join(dataset_path,'train_images(sub_all_type).zip')\n","train_ann_path = os.path.join(dataset_path,'train_labelTxt_main.zip')\n","\n","output_path = '/content/mmrotate/data/split_ss_dota/'\n","os.makedirs(output_path, exist_ok=True)\n","\n","\n","train_output_path = '/content/mmrotate/data/split_ss_dota/train'\n","\n","\n","# unzip \n","extract_zip(train_img_path,'/content/mmrotate/data/split_ss_dota/train/images')\n","extract_zip(train_ann_path,'/content/mmrotate/data/split_ss_dota/train/annfiles')\n","\n","# os.rename('/content/mmrotate/data/split_ss_dota/train/train_annfiles','/content/mmrotate/data/split_ss_dota/train/annfiles')\n","# os.rename('/content/mmrotate/data/split_ss_dota/train/train_images','/content/mmrotate/data/split_ss_dota/train/images')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1lc4tPtMPI-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664155109107,"user_tz":-540,"elapsed":499694,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}},"outputId":"8d137941-0891-4345-f843-89d7c7bf1a30"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/val_images(sub_all_type).zip Unzip Complete\n","/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/val_images(sub_all_type).zip  Unzip Time: 496.4332sec\n","/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/val_labelTxt_main.zip Unzip Complete\n","/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/val_labelTxt_main.zip  Unzip Time: 1.2701sec\n"]}],"source":["# validation\n","dataset_path = '/content/drive/MyDrive/00.AIFFEL/03.해커톤/00.SIA 해커톤/00.잘할거SIA/data/'\n","\n","validation_img_path = os.path.join(dataset_path,'val_images(sub_all_type).zip')\n","validation_ann_path = os.path.join(dataset_path,'val_labelTxt_main.zip')\n","\n","output_path = '/content/mmrotate/data/split_ss_dota/'\n","os.makedirs(output_path, exist_ok=True)\n","\n","\n","val_output_path = '/content/mmrotate/data/split_ss_dota/val'\n","\n","\n","# unzip \n","extract_zip(validation_img_path,val_output_path + '/images')\n","extract_zip(validation_ann_path,val_output_path + '/annfiles')"]},{"cell_type":"code","source":["# convert tif to png  (-> )\n","\n","def convert_tif_to_png(img_dir):\n","    import os\n","    tif_files = os.listdir(img_dir)\n","    for tif_file in tif_files:\n","        png_file = tif_file.replace('.tif','.png')\n","        os.replace(f\"{img_dir}/{tif_file}\", f\"{img_dir}/{png_file}\")\n","    print(img_dir,': convert complete')\n","\n","train_img_dir = '/content/mmrotate/data/split_ss_dota/train/images'\n","val_img_dir = '/content/mmrotate/data/split_ss_dota/val/images'\n","\n","convert_tif_to_png(train_img_dir)\n","convert_tif_to_png(val_img_dir)"],"metadata":{"id":"LWrh1TjkOoR6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664155109746,"user_tz":-540,"elapsed":642,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}},"outputId":"5f541329-1151-4da9-d856-842d18a5b82e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmrotate/data/split_ss_dota/train/images : convert complete\n","/content/mmrotate/data/split_ss_dota/val/images : convert complete\n"]}]},{"cell_type":"markdown","metadata":{"id":"qUtlAkNPMpuf"},"source":["#Config file "]},{"cell_type":"markdown","metadata":{"id":"a_QUqhsHFL-r"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mc0ObJSNG-n"},"outputs":[],"source":["\n","########################## 새로운 데이터셋 정의 : FAIR1MDataset 클래스를 생성하여 fair1m.py 생성하기 ############################\n","\n","FAIR1MDataset_text = '''\n","\n","from .builder import ROTATED_DATASETS\n","from .dota import DOTADataset\n","import os\n","import os.path as osp\n","import xml.etree.ElementTree as ET\n","from collections import OrderedDict\n","import numpy as np\n","from PIL import Image\n","from mmrotate.core import eval_rbbox_map\n","\n","\n","@ROTATED_DATASETS.register_module()\n","class FAIR1MDataset(DOTADataset):\n","    \"\"\"fair1m dataset for detection \"\"\"\n","    CLASSES = ('Airplane','Ship', 'Vehicle')\n","    PALETTE = [(165, 42, 42), (189, 183, 107), (0, 255, 0)]\n","\n","    def __init__(self, **kwargs):\n","        super(FAIR1MDataset, self).__init__(**kwargs)\n","\n","    def evaluate(self,\n","                 results,\n","                 metric= ['mAP','F1Score'],\n","                 logger=None,\n","                 proposal_nums=(100, 300, 1000),\n","                 iou_thr=0.5,\n","                 scale_ranges=None,\n","                 nproc=4):\n","\n","        \"\"\"Evaluate the dataset.\n","        Args:\n","            results (list): Testing results of the dataset.\n","            metric (str | list[str]): Metrics to be evaluated.\n","            logger (logging.Logger | None | str): Logger used for printing\n","                related information during evaluation. Default: None.\n","            proposal_nums (Sequence[int]): Proposal number used for evaluating\n","                recalls, such as recall@100, recall@1000.\n","                Default: (100, 300, 1000).\n","            iou_thr (float | list[float]): IoU threshold. It must be a float\n","                when evaluating mAP, and can be a list when evaluating recall.\n","                Default: 0.5.\n","            scale_ranges (list[tuple] | None): Scale ranges for evaluating mAP.\n","                Default: None.\n","            use_07_metric (bool): Whether to use the voc07 metric.\n","            nproc (int): Processes used for computing TP and FP.\n","                Default: 4.\n","        \"\"\"\n","        \n","        # super().evaluate()\n","        nproc = min(nproc, os.cpu_count())\n","\n","        # metric 이 없으면 mAP,F1Score 쓰기\n","        if not isinstance(metric, str):\n","            assert len(metric) == 2\n","            metric = metric\n","        \n","        # allowed_metrics 외 metric을 적으면 해당 메트릭은 지원하지 않는다는 예외처리하기   \n","        allowed_metrics = ['mAP','F1Score']\n","        if metric not in allowed_metrics:\n","            raise KeyError(f'metric {metric} is not supported')\n","\n","        annotations = [self.get_ann_info(i) for i in range(len(self))]\n","        eval_results = {}\n","\n","\n","        # mAP, F1Score metric 정의 (metric으로 mAP, F1Score 두개 다 썼을때 )\n","        if ('mAP' and 'F1Score') in metric  :\n","            assert isinstance(iou_thr, float)\n","\n","            mean_ap, mean_f1, _ = eval_rbbox_map(\n","                results,\n","                annotations,\n","                scale_ranges=scale_ranges,\n","                iou_thr=iou_thr,\n","                dataset=self.CLASSES,\n","                logger=logger,\n","                nproc=nproc)\n","            eval_results['mAP'] = mean_ap\n","            eval_results['F1Score'] = mean_f1\n","\n","        # mAP metric 정의 (mAP 일때는 iou별 AP 도 같이 계산해야함)\n","        if metric == 'mAP' :\n","            assert isinstance(iou_thr, float)\n","            mean_ap, _, _ = eval_rbbox_map(\n","                results,\n","                annotations,\n","                scale_ranges=scale_ranges,\n","                iou_thr=iou_thr,\n","                dataset=self.CLASSES,\n","                logger=logger,\n","                nproc=nproc)\n","            eval_results['mAP'] = mean_ap\n","\n","\n","        # F1Score metric 정의    \n","        elif metric == 'F1Score':\n","            assert isinstance(iou_thr, float)\n","            _, mean_f1, _ = eval_rbbox_map(\n","                results,\n","                annotations,\n","                scale_ranges=scale_ranges,\n","                iou_thr=iou_thr,\n","                dataset=self.CLASSES,\n","                logger=logger,\n","                nproc=nproc)\n","            eval_results['F1Score'] = mean_f1\n","\n","\n","        else:\n","            raise NotImplementedError\n","\n","        return eval_results\n","        \n","'''\n","\n","FAIR1MDataset_path = '/content/mmrotate/mmrotate/datasets/fair1m.py'\n","\n","f = open(FAIR1MDataset_path, \"w\")\n","f.write(FAIR1MDataset_text)\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wScteQSFEfdH"},"outputs":[],"source":["FAIR1MDataset_init = '''\n","# Copyright (c) OpenMMLab. All rights reserved.\n","from .builder import build_dataset  # noqa: F401, F403\n","from .dota import DOTADataset  # noqa: F401, F403\n","from .hrsc import HRSCDataset  # noqa: F401, F403\n","from .pipelines import *  # noqa: F401, F403\n","from .sar import SARDataset  # noqa: F401, F403\n","from .fair1m import FAIR1MDataset\n","\n","__all__ = ['SARDataset', 'FAIR1MDataset', 'DOTADataset', 'build_dataset', 'HRSCDataset']\n","'''\n","\n","FAIR1MDataset_init_path = '/content/mmrotate/mmrotate/datasets/__init__.py'\n","\n","f = open(FAIR1MDataset_init_path, \"w\")\n","f.write(FAIR1MDataset_init)\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"XF0GCL_YFOdk"},"source":["## eval_map"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4lC_5XbFRk5"},"outputs":[],"source":["########## eval_map ############\n","\n","eval_map = '''\n","\n","# Copyright (c) OpenMMLab. All rights reserved.\n","from multiprocessing import get_context\n","\n","import numpy as np\n","import torch\n","from mmcv.ops import box_iou_rotated\n","from mmcv.utils import print_log\n","from mmdet.core import average_precision\n","from terminaltables import AsciiTable\n","\n","# tpfp 가려내는 함수 -> 밑에선 클래스 별로 계산함\n","def tpfp_default(det_bboxes,\n","                 gt_bboxes,\n","                 gt_bboxes_ignore=None,\n","                 iou_thr=0.5,\n","                 area_ranges=None):\n","    \"\"\"Check if detected bboxes are true positive or false positive.\n","\n","    Args:\n","        det_bboxes (ndarray): Detected bboxes of this image, of shape (m, 6).\n","        gt_bboxes (ndarray): GT bboxes of this image, of shape (n, 5).\n","        gt_bboxes_ignore (ndarray): Ignored gt bboxes of this image,\n","            of shape (k, 5). Default: None\n","        iou_thr (float): IoU threshold to be considered as matched.\n","            Default: 0.5.\n","        area_ranges (list[tuple] | None): Range of bbox areas to be evaluated,\n","            in the format [(min1, max1), (min2, max2), ...]. Default: None.\n","\n","    Returns:\n","        tuple[np.ndarray]: (tp, fp) whose elements are 0 and 1. The shape of\n","            each array is (num_scales, m).\n","    \"\"\"\n","\n","    # an indicator of ignored gts\n","    det_bboxes = np.array(det_bboxes)\n","    gt_ignore_inds = np.concatenate(\n","        # gt_bboxes는 밑에서 결과에 따라 0,1로 바꾸는거고. gt_bboxes_ignore은 우선 ignore 이니까 다 1로 해놓음\n","        (np.zeros(gt_bboxes.shape[0], dtype=np.bool),\n","         np.ones(gt_bboxes_ignore.shape[0], dtype=np.bool)))\n","    # stack gt_bboxes and gt_bboxes_ignore for convenience\n","    gt_bboxes = np.vstack((gt_bboxes, gt_bboxes_ignore))\n","\n","    num_dets = det_bboxes.shape[0]\n","    num_gts = gt_bboxes.shape[0]\n","    if area_ranges is None:\n","        area_ranges = [(None, None)]\n","    num_scales = len(area_ranges) # num_scales == 1 is None else 2???\n","    # tp and fp are of shape (num_scales, num_gts), each row is tp or fp of\n","    # a certain scale [[ 0, 이 num_dets개 ]]\n","    tp = np.zeros((num_scales, num_dets), dtype=np.float32)\n","    fp = np.zeros((num_scales, num_dets), dtype=np.float32)\n","\n","####################### 이미지에 gt가 없음 ########################################\n","    # 이번 이미지에서 gt가 없으면 det전부를 fp로 변경\n","    if gt_bboxes.shape[0] == 0:\n","        if area_ranges == [(None, None)]:\n","            # fp 전체를 1로 바꿈\n","            fp[...] = 1\n","        else:\n","            raise NotImplementedError\n","        return tp, fp\n","\n","######################## 이미지에 gt가 있음 #########################################\n","    # 이미지에 gt가 있는 상태에서 iou에따른 tp, fp 계산\n","    ious = box_iou_rotated(\n","        torch.from_numpy(det_bboxes).float(),\n","        torch.from_numpy(gt_bboxes).float()).numpy()\n","\n","    # for each det, the max iou with all gts\n","    # 열 중에서(axis = 1) 큰 원소를 반환\n","    ious_max = ious.max(axis=1)\n","    # for each det, which gt overlaps most with it\n","    # 열 중에서(axis = 1) 큰 원소의 인덱스를 반환\n","    ious_argmax = ious.argmax(axis=1)\n","    # sort all dets in descending order by scores 스코어 제일 높은 값 sort_inds??\n","    sort_inds = np.argsort(-det_bboxes[:, -1]) # shape of det_bboxes : (m, 6)\n","    for k, (min_area, max_area) in enumerate(area_ranges):\n","        gt_covered = np.zeros(num_gts, dtype=bool)\n","        # area_ranges가 지정되지 않은 경우 gt_area_ignore는 모두 False입니다.\n","        if min_area is None:\n","            gt_area_ignore = np.zeros_like(gt_ignore_inds, dtype=bool)\n","        else:\n","            raise NotImplementedError\n","        for i in sort_inds:\n","            # 스코어 높은 값을 하나씩 꺼내서 그 값이 IOU thres 보다 높으면 그걸로 gt랑 매칭함\n","            if ious_max[i] >= iou_thr:\n","                matched_gt = ious_argmax[i]\n","                if not (gt_ignore_inds[matched_gt]\n","                        or gt_area_ignore[matched_gt]):\n","                    if not gt_covered[matched_gt]:\n","                        gt_covered[matched_gt] = True\n","                    # 매칭한 gt가 ignore이 아니고 gts에 있으면 tp / 아니면 fp\n","                        tp[k, i] = 1\n","                    else:\n","                        fp[k, i] = 1\n","                # otherwise ignore this detected bbox, tp = 0, fp = 0\n","            elif min_area is None:\n","                fp[k, i] = 1\n","            else:\n","                bbox = det_bboxes[i, :5]\n","                area = bbox[2] * bbox[3]\n","                if area >= min_area and area < max_area:\n","                    fp[k, i] = 1\n","    return tp, fp\n","\n","\n","# 디텍팅한 결과값을 가져와서 우리가 원하는 클래스에 있으면, 클래스 별로 \n","def get_cls_results(det_results, annotations, class_id):\n","    \"\"\"Get det results and gt information of a certain class.\n","\n","    Args:\n","        det_results (list[list]): \n","            det_results (list[list]): [[cls1_det, cls2_det, ...], ...].\n","            The outer list indicates images, \n","            and the inner list indicates per-class detected bboxes.\n","            => len(det_results) == 이미지 갯수, len(det_results[0]) == 클래스별로 감지된 bbox 갯수 \n","        annotations (list[dict]): Same as `eval_map()`.\n","        class_id (int): ID of a specific class.\n","\n","    Returns:\n","        tuple[list[np.ndarray]]: detected bboxes, gt bboxes, ignored gt bboxes\n","    \"\"\"\n","    # 디텍트 결과에서 이미지별 클래스 뽑아냄\n","    cls_dets = [img_res[class_id] for img_res in det_results]\n","\n","    cls_gts = []\n","    cls_gts_ignore = []\n","    for ann in annotations:\n","        #어노테이션의 라벨이 클래스 id에 있으면 그 박스들을 cls_gt에 넣음\n","        gt_inds = ann['labels'] == class_id\n","        cls_gts.append(ann['bboxes'][gt_inds, :])\n","        # labels_ignore 값이 있으면 그 클래스 id는 cls_gts_ignore 값에 넣음\n","        if ann.get('labels_ignore', None) is not None:\n","            ignore_inds = ann['labels_ignore'] == class_id\n","            cls_gts_ignore.append(ann['bboxes_ignore'][ignore_inds, :])\n","\n","        else:\n","            cls_gts_ignore.append(torch.zeros((0, 5), dtype=torch.float64))\n","\n","    #cls_dets : 총 디텍트 결과, cls_gts : 디텍팅 결과에서 지정 클래스인것, cls_gts_ignore : 무시 값 \n","    return cls_dets, cls_gts, cls_gts_ignore\n","\n","\n","def eval_rbbox_map(det_results,\n","                   annotations,\n","                   scale_ranges=None,\n","                   iou_thr=0.5,\n","                   use_07_metric=True,\n","                   dataset=None,\n","                   logger=None,\n","                   nproc=4):\n","    \"\"\"Evaluate mAP of a rotated dataset.\n","\n","    Args:\n","        det_results (list[list]): 이미지 마다 디텍팅한 클래스 별 bbox\n","            [[cls1_det, cls2_det, ...], ...].\n","            The outer list indicates images, and the inner list indicates\n","            per-class detected bboxes.\n","        annotations (list[dict]): gt annotation an image\n","        Ground truth annotations where each item of the list indicates an image. \n","        Keys of annotations are:\n","            - `bboxes`: numpy array of shape (n, 5) => n개가 5포인트로\n","            - `labels`: numpy array of shape (n, ) => n개의 클래스\n","            - `bboxes_ignore` (optional): numpy array of shape (k, 5) => 무시할 비박스\n","            - `labels_ignore` (optional): numpy array of shape (k, ) => 무시할 클래스\n","\n","        scale_ranges (list[tuple] | None): 계산할 size min-max 지정\n","            Range of scales to be evaluated, in the format [(min1, max1), (min2, max2), ...]. \n","            A range of (32, 64) means the area range between (32**2, 64**2).\n","            Default: None.\n","\n","        iou_thr (float): IoU threshold to be considered as matched.\n","            Default: 0.5.\n","\n","        use_07_metric (bool): Whether to use the voc07 metric.\n","        dataset (list[str] | str | None): Dataset name or dataset classes,\n","            there are minor differences in metrics for different datasets, e.g.\n","            \"voc07\", \"imagenet_det\", etc. Default: None.\n","\n","        logger (logging.Logger | str | None): The way to print the mAP\n","            summary. See `mmcv.utils.print_log()` for details. Default: None.\n","        nproc (int): Processes used for computing TP and FP.\n","            Default: 4.\n","\n","    Returns:\n","        tuple: (mAP, [dict, dict, ...])\n","    \"\"\"\n","    #이미지수랑 어노테이션 수 안맞으면 오류!\n","    assert len(det_results) == len(annotations)\n","\n","\n","    num_imgs = len(det_results)\n","    num_scales = len(scale_ranges) if scale_ranges is not None else 1\n","    num_classes = len(det_results[0])  # positive class num // len(det_results[0]) == 클래스별로 감지된 bbox 갯수 \n","    area_ranges = ([(rg[0]**2, rg[1]**2) for rg in scale_ranges]\n","                   if scale_ranges is not None else None)\n","\n","    pool = get_context('spawn').Pool(nproc)\n","    eval_results = []\n","    # 클래스 별로 계산\n","    for i in range(num_classes):\n","        # get gt and det bboxes of this class\n","        #cls_dets : 총 디텍트 결과, cls_gts : 디텍팅 결과에서 지정 클래스인것, cls_gts_ignore : 무시 값 \n","        cls_dets, cls_gts, cls_gts_ignore = get_cls_results(\n","            det_results, annotations, i)\n","\n","        # compute tp and fp for each image with multiple processes\n","        tpfp = pool.starmap(\n","            tpfp_default,\n","            zip(cls_dets, cls_gts, cls_gts_ignore,\n","                [iou_thr for _ in range(num_imgs)],\n","                [area_ranges for _ in range(num_imgs)]))\n","        tp, fp = tuple(zip(*tpfp))\n","\n","        # calculate gt number of each scale\n","        # ignored gts or gts beyond the specific scale are not counted\n","        # num_gts : area_ranges 없으면 디텍팅 결과에서 지정 클래스인 수, 있으면 사이즈에 맞는 수만 들어감\n","        num_gts = np.zeros(num_scales, dtype=int)\n","        for _, bbox in enumerate(cls_gts):\n","            if area_ranges is None:\n","                num_gts[0] += bbox.shape[0]\n","            else:\n","                gt_areas = bbox[:, 2] * bbox[:, 3]\n","                for k, (min_area, max_area) in enumerate(area_ranges):\n","                    num_gts[k] += np.sum((gt_areas >= min_area)\n","                                         & (gt_areas < max_area))\n","        # sort all det bboxes by score, also sort tp and fp\n","        cls_dets = np.vstack(cls_dets)\n","        num_dets = cls_dets.shape[0]\n","        sort_inds = np.argsort(-cls_dets[:, -1])\n","        tp = np.hstack(tp)[:, sort_inds]\n","        fp = np.hstack(fp)[:, sort_inds]\n","\n","        # calculate recall and precision with tp and fp\n","        tp = np.cumsum(tp, axis=1)\n","        fp = np.cumsum(fp, axis=1)\n","        eps = np.finfo(np.float32).eps\n","        recalls = tp / np.maximum(num_gts[:, np.newaxis], eps) # num_gts가 gt수니까\n","        precisions = tp / np.maximum((tp + fp), eps)\n","\n","        # calculate AP\n","        # scale_ranges 지정 되어 있으면 rec, prec, num_gts 값 변경\n","        if scale_ranges is None:\n","            recalls = recalls[0, :]\n","            precisions = precisions[0, :]\n","            num_gts = num_gts.item()\n","        mode = 'area' if not use_07_metric else '11points'\n","        ap = average_precision(recalls, precisions, mode)\n","        # calculate F1 추가\n","        f1_score = 2 * precisions * recalls / np.maximum((precisions+recalls),eps)\n","        f1_score = f1_score.mean()\n","\n","        eval_results.append({\n","            'num_gts': num_gts,\n","            'num_dets': num_dets,\n","            'recall': recalls,\n","            'precision': precisions,\n","            'ap': ap,\n","            'F1' : f1_score\n","        })\n","    pool.close()\n","\n","    # 클래스 별로 계산끝@ eval_results에 클래스별로 값 들어가있음\n","    \n","    # 만약 scale_ranges 가 지정되어 있으면,\n","    if scale_ranges is not None:\n","        # shape (num_classes, num_scales)\n","        ##### mF1 score 추가\n","        all_ap = np.vstack([cls_result['ap'] for cls_result in eval_results])\n","        all_f1 = np.vstack([cls_result['F1'] for cls_result in eval_results])\n","        all_num_gts = np.vstack(\n","            [cls_result['num_gts'] for cls_result in eval_results])\n","        mean_ap = []\n","        mean_f1 = []\n","        # 스케일별로 mean값 뽑아서 mean_리스트에 넣음 [1클래스 ap 평균, 2클래스 ap 평균, ...]\n","        for i in range(num_scales):\n","            if np.any(all_num_gts[:, i] > 0):\n","                mean_ap.append(all_ap[all_num_gts[:, i] > 0, i].mean())\n","                mean_f1.append(all_f1[all_num_gts[:, i] > 0, i].mean())\n","            else:\n","                mean_ap.append(0.0)\n","                mean_f1.append(0.0)\n","\n","    # scale_ranges 없으면 클래스별로 리스트에 넣어서 평균냄\n","    else:\n","        aps = []\n","        f1s = []\n","\n","        for cls_result in eval_results:\n","            # 클래스의 gt가 있으면, 각 클래스별 ap, f1값 각각 리스트에 넣음 aps = [1클래스 ap, 2클래스 ap, ...]\n","            if cls_result['num_gts'] > 0:\n","                aps.append(cls_result['ap'])\n","                f1s.append(cls_result['F1'])\n","\n","        mean_ap = np.array(aps).mean() if aps else 0.0\n","        mean_f1 = np.array(f1s).mean() if f1s else 0.0\n","\n","    print_map_summary(\n","        mean_ap, mean_f1, eval_results, dataset, area_ranges, logger=logger)\n","\n","    return mean_ap, mean_f1, eval_results\n","    \n","    # eval_results에 클래스별로 걊들어가있음\n","\n","def print_map_summary(mean_ap,\n","                      mean_f1,\n","                      results,\n","                      dataset=None,\n","                      scale_ranges=None,\n","                      logger=None):\n","\n","    \"\"\"Print mAP and results of each class.\n","\n","    A table will be printed to show the gts/dets/recall/AP/F1!!!!! of each class and\n","    the mAP,mF1.\n","\n","    Args:\n","        mean_ap (float): Calculated from `eval_map()`.\n","        mean_f1 (list): Calculated from `eval_map()`. \n","            mean_f1 = [weighted_f1, macro_f1]\n","        results (list[dict]): Calculated from `eval_map()`.\n","        dataset (list[str] | str | None): Dataset name or dataset classes.\n","        scale_ranges (list[tuple] | None): Range of scales to be evaluated.\n","        logger (logging.Logger | str | None): The way to print the mAP\n","            summary. See `mmcv.utils.print_log()` for details. Default: None.\n","    \"\"\"\n","\n","    if logger == 'silent':\n","        return\n","\n","    # scale_ranges 있었는지 확인하는 듯\n","    if isinstance(results[0]['ap'], np.ndarray):\n","        num_scales = len(results[0]['ap']) # 클래스 1의 ap?\n","    else:\n","        num_scales = 1\n","\n","    # scale_ranges가 있으면, 계산할때랑 맞는지 확인함\n","    if scale_ranges is not None:\n","        assert len(scale_ranges) == num_scales\n","\n","    num_classes = len(results)\n","\n","    # 각 값들 (0,0,0)으로 세팅\n","    recalls = np.zeros((num_scales, num_classes), dtype=np.float32) \n","    precisions = np.zeros((num_scales, num_classes), dtype=np.float32) \n","    aps = np.zeros((num_scales, num_classes), dtype=np.float32)\n","    f1s = np.zeros((num_scales, num_classes), dtype=np.float32)\n","    num_gts = np.zeros((num_scales, num_classes), dtype=int)\n","    for i, cls_result in enumerate(results):\n","        #클래스별로 꺼내는데, recall값이 있으면,\n","        if cls_result['recall'].size > 0:\n","            recalls[:, i] = np.array(cls_result['recall'], ndmin=2)[:, -1]\n","            precisions[:, i] = np.array(cls_result['precision'], ndmin=2)[:, -1]\n","        aps[:, i] = cls_result['ap']\n","        f1s[:, i] = cls_result['F1']\n","        num_gts[:, i] = cls_result['num_gts']\n","\n","    if dataset is None:\n","        label_names = [str(i) for i in range(num_classes)]\n","    else:\n","        label_names = dataset\n","\n","    if not isinstance(mean_ap, list):\n","        mean_ap = [mean_ap]\n","\n","    if not isinstance(mean_f1, list):\n","        mean_f1 = [mean_f1]\n","\n","    header = ['class', 'gts', 'dets', 'recall', 'precision', 'ap', 'F1']\n","    for i in range(num_scales):\n","        if scale_ranges is not None:\n","            print_log(f'Scale range {scale_ranges[i]}', logger=logger)\n","        table_data = [header]\n","        for j in range(num_classes):\n","            row_data = [\n","                label_names[j], num_gts[i, j], results[j]['num_dets'],\n","                f'{recalls[i, j]:.3f}', f'{precisions[i, j]:.3f}', f'{aps[i, j]:.3f}', f'{f1s[i, j]:.3f}'\n","            ]\n","            table_data.append(row_data)\n","        append_data = ['mAP, mF1', '', '', '','', f'{mean_ap[i]:.3f}', f'{mean_f1[i]:.3f}']\n","        table_data.append(append_data)\n","        table = AsciiTable(table_data)\n","        table.inner_footing_row_border = True\n","        print_log('\\\\n' + table.table, logger=logger)\n","\n","'''\n","\n","eval_map_path = '/content/mmrotate/mmrotate/core/evaluation/eval_map.py'\n","\n","f = open(eval_map_path, \"w\")\n","f.write(eval_map)\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"TGZmC4xkFviT"},"source":["## model"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"JFeXRXe-Fw17","executionInfo":{"status":"ok","timestamp":1664156498506,"user_tz":-540,"elapsed":504,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}}},"outputs":[],"source":["model_config = '''\n","\n","dataset_type = 'FAIR1MDataset'\n","data_root = '/content/mmrotate/data/split_ss_dota/'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(type='RResize', img_scale=(1024, 1024), multiscale_mode='range'),\n","    dict(type='RRandomCrop', crop_size=(512, 512)),\n","    dict(\n","        type='RRandomFlip',\n","        flip_ratio=[0.25, 0.25, 0.25],\n","        direction=['horizontal', 'vertical', 'diagonal'],\n","        version='le90'),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size_divisor=32),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(1024, 1024),\n","        flip=False,\n","        transforms=[\n","            dict(type='RResize'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=2,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type='FAIR1MDataset',\n","        ann_file='/content/mmrotate/data/split_ss_dota/train/annfiles/',\n","        img_prefix='/content/mmrotate/data/split_ss_dota/train/images/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(type='RResize', img_scale=(1024, 1024), multiscale_mode='range'),\n","            dict(type='RRandomCrop', crop_size=(512, 512)),\n","            dict(\n","                type='RRandomFlip',\n","                flip_ratio=[0.25, 0.25, 0.25],\n","                direction=['horizontal', 'vertical', 'diagonal'],\n","                version='le90'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","        ],\n","        version='le90'),\n","    val=dict(\n","        type='FAIR1MDataset',\n","        ann_file='/content/mmrotate/data/split_ss_dota/val/annfiles/',\n","        img_prefix='/content/mmrotate/data/split_ss_dota/val/images/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1024, 1024),\n","                flip=False,\n","                transforms=[\n","                    dict(type='RResize'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='DefaultFormatBundle'),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        version='le90'),\n","    test=dict(\n","        type='FAIR1MDataset',\n","        ann_file='/content/mmrotate/data/split_ss_dota/val/annfiles/',\n","        img_prefix='/content/mmrotate/data/split_ss_dota/val/images/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1024, 1024),\n","                flip=False,\n","                transforms=[\n","                    dict(type='RResize'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='DefaultFormatBundle'),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        version='le90'))\n","evaluation = dict(interval=1, metric='mAP' and 'F1Score')\n","optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0001)\n","optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n","lr_config = dict(\n","    policy='step',\n","    warmup='linear',\n","    warmup_iters=500,\n","    warmup_ratio=0.3333333333333333,\n","    step=[8, 11])\n","runner = dict(type='EpochBasedRunner', max_epochs=12)\n","checkpoint_config = dict(interval=1)\n","log_config = dict(\n","    interval=50,\n","    hooks=[\n","        dict(type='TextLoggerHook', interval=50),\n","        dict(type='WandbLoggerHook',interval=100,\n","            init_kwargs=dict(\n","                project='SIA_Project',\n","                entity = 'jhgsia',\n","                name = 'head_anchor_ratio_[0.5, 1.0, 1.5, 4.0]' ###################### <---------------- 여기서 프로젝트에 들어가는 이름 설정#####################\n","            ),\n","            )\n","    ])\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","opencv_num_threads = 0\n","mp_start_method = 'fork'\n","angle_version = 'le90'\n","model = dict(\n","    type='OrientedRCNN',\n","    backbone=dict(\n","        type='ResNet',\n","        depth=50,\n","        num_stages=4,\n","        out_indices=(0, 1, 2, 3),\n","        frozen_stages=1,\n","        norm_cfg=dict(type='BN', requires_grad=True),\n","        norm_eval=True,\n","        style='pytorch',\n","        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n","    neck=dict(\n","        type='FPN',\n","        in_channels=[256, 512, 1024, 2048],\n","        out_channels=256,\n","        num_outs=5),\n","    rpn_head=dict(\n","        type='OrientedRPNHead',\n","        in_channels=256,\n","        feat_channels=256,\n","        version='le90',\n","        anchor_generator=dict(\n","            type='AnchorGenerator',\n","            scales=[8],\n","            ratios=[0.5, 1.0, 1.5, 4.0],     ###################### <------------여기 자기가 맡은 ratio로 수정 ##################\n","            strides=[4, 8, 16, 32, 64]),\n","        bbox_coder=dict(\n","            type='MidpointOffsetCoder',\n","            angle_range='le90',\n","            target_means=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n","            target_stds=[1.0, 1.0, 1.0, 1.0, 0.5, 0.5]),\n","        loss_cls=dict(\n","            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n","        loss_bbox=dict(\n","            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n","    roi_head=dict(\n","        type='OrientedStandardRoIHead',\n","        bbox_roi_extractor=dict(\n","            type='RotatedSingleRoIExtractor',\n","            roi_layer=dict(\n","                type='RoIAlignRotated',\n","                out_size=7,\n","                sample_num=2,\n","                clockwise=True),\n","            out_channels=256,\n","            featmap_strides=[4, 8, 16, 32]),\n","        bbox_head=dict(\n","            type='RotatedShared2FCBBoxHead',\n","            in_channels=256,\n","            fc_out_channels=1024,\n","            roi_feat_size=7,\n","            num_classes=3,\n","            bbox_coder=dict(\n","                type='DeltaXYWHAOBBoxCoder',\n","                angle_range='le90',\n","                norm_factor=None,\n","                edge_swap=True,\n","                proj_xy=True,\n","                target_means=(0.0, 0.0, 0.0, 0.0, 0.0),\n","                target_stds=(0.1, 0.1, 0.2, 0.2, 0.1)),\n","            reg_class_agnostic=True,\n","            loss_cls=dict(\n","                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n","            loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))),\n","    train_cfg=dict(\n","        rpn=dict(\n","            assigner=dict(\n","                type='MaxIoUAssigner',\n","                pos_iou_thr=0.7,\n","                neg_iou_thr=0.3,\n","                min_pos_iou=0.3,\n","                match_low_quality=True,\n","                ignore_iof_thr=-1),\n","            sampler=dict(\n","                type='RandomSampler',\n","                num=256,\n","                pos_fraction=0.5,\n","                neg_pos_ub=-1,\n","                add_gt_as_proposals=False),\n","            allowed_border=0,\n","            pos_weight=-1,\n","            debug=False),\n","        rpn_proposal=dict(\n","            nms_pre=2000,\n","            max_per_img=2000,\n","            nms=dict(type='nms', iou_threshold=0.8),\n","            min_bbox_size=0),\n","        rcnn=dict(\n","            assigner=dict(\n","                type='MaxIoUAssigner',\n","                pos_iou_thr=0.5,\n","                neg_iou_thr=0.5,\n","                min_pos_iou=0.5,\n","                match_low_quality=False,\n","                iou_calculator=dict(type='RBboxOverlaps2D'),\n","                ignore_iof_thr=-1),\n","            sampler=dict(\n","                type='RRandomSampler',\n","                num=512,\n","                pos_fraction=0.25,\n","                neg_pos_ub=-1,\n","                add_gt_as_proposals=True),\n","            pos_weight=-1,\n","            debug=False)),\n","    test_cfg=dict(\n","        rpn=dict(\n","            nms_pre=2000,\n","            max_per_img=2000,\n","            nms=dict(type='nms', iou_threshold=0.8),\n","            min_bbox_size=0),\n","        rcnn=dict(\n","            nms_pre=2000,\n","            min_bbox_size=0,\n","            score_thr=0.05,\n","            nms=dict(iou_thr=0.1),\n","            max_per_img=2000)))\n","\n","'''\n","\n","model_config_path = '/content/mmrotate/configs/oriented_rcnn/oriented_rcnn_r50_fpn_1x_dota_le90.py'\n","\n","f = open(model_config_path, \"w\")\n","f.write(model_config)\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"ZI4UyqdXNFRf"},"source":["#Train!"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"6qyTifpQMdue","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664155922841,"user_tz":-540,"elapsed":2,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}},"outputId":"61a5083f-ec9e-4e22-e92c-582a88f41c95"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmrotate\n"]}],"source":["%cd /content/mmrotate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hT9H0_AoMpfO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9224775-7326-4d01-f70a-bab5cd97c495"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmrotate/mmrotate/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n","  f'Setting OMP_NUM_THREADS environment variable for each process '\n","/content/mmrotate/mmrotate/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n","  f'Setting MKL_NUM_THREADS environment variable for each process '\n","2022-09-26 01:41:47,892 - mmrotate - INFO - Environment info:\n","------------------------------------------------------------\n","sys.platform: linux\n","Python: 3.7.14 (default, Sep  8 2022, 00:06:44) [GCC 7.5.0]\n","CUDA available: True\n","GPU 0: Tesla P100-PCIE-16GB\n","CUDA_HOME: /usr/local/cuda\n","NVCC: Cuda compilation tools, release 11.1, V11.1.105\n","GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","PyTorch: 1.12.1+cu113\n","PyTorch compiling details: PyTorch built with:\n","  - GCC 9.3\n","  - C++ Version: 201402\n","  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX2\n","  - CUDA Runtime 11.3\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n","  - CuDNN 8.3.2  (built against CUDA 11.5)\n","  - Magma 2.5.2\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n","\n","TorchVision: 0.13.1+cu113\n","OpenCV: 4.6.0\n","MMCV: 1.6.0\n","MMCV Compiler: GCC 9.3\n","MMCV CUDA Compiler: 11.3\n","MMRotate: 0.3.2+c62f148\n","------------------------------------------------------------\n","\n","2022-09-26 01:41:48,248 - mmrotate - INFO - Distributed training: False\n","2022-09-26 01:41:48,481 - mmrotate - INFO - Config:\n","dataset_type = 'FAIR1MDataset'\n","data_root = '/content/mmrotate/data/split_ss_dota/'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(type='RResize', img_scale=(1024, 1024), multiscale_mode='range'),\n","    dict(type='RRandomCrop', crop_size=(512, 512)),\n","    dict(\n","        type='RRandomFlip',\n","        flip_ratio=[0.25, 0.25, 0.25],\n","        direction=['horizontal', 'vertical', 'diagonal'],\n","        version='le90'),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size_divisor=32),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(1024, 1024),\n","        flip=False,\n","        transforms=[\n","            dict(type='RResize'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=2,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type='FAIR1MDataset',\n","        ann_file='/content/mmrotate/data/split_ss_dota/train/annfiles/',\n","        img_prefix='/content/mmrotate/data/split_ss_dota/train/images/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(\n","                type='RResize',\n","                img_scale=(1024, 1024),\n","                multiscale_mode='range'),\n","            dict(type='RRandomCrop', crop_size=(512, 512)),\n","            dict(\n","                type='RRandomFlip',\n","                flip_ratio=[0.25, 0.25, 0.25],\n","                direction=['horizontal', 'vertical', 'diagonal'],\n","                version='le90'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","        ],\n","        version='le90'),\n","    val=dict(\n","        type='FAIR1MDataset',\n","        ann_file='/content/mmrotate/data/split_ss_dota/val/annfiles/',\n","        img_prefix='/content/mmrotate/data/split_ss_dota/val/images/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1024, 1024),\n","                flip=False,\n","                transforms=[\n","                    dict(type='RResize'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='DefaultFormatBundle'),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        version='le90'),\n","    test=dict(\n","        type='FAIR1MDataset',\n","        ann_file='/content/mmrotate/data/split_ss_dota/val/annfiles/',\n","        img_prefix='/content/mmrotate/data/split_ss_dota/val/images/',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1024, 1024),\n","                flip=False,\n","                transforms=[\n","                    dict(type='RResize'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='DefaultFormatBundle'),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        version='le90'))\n","evaluation = dict(interval=1, metric='F1Score')\n","optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0001)\n","optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n","lr_config = dict(\n","    policy='step',\n","    warmup='linear',\n","    warmup_iters=500,\n","    warmup_ratio=0.3333333333333333,\n","    step=[8, 11])\n","runner = dict(type='EpochBasedRunner', max_epochs=12)\n","checkpoint_config = dict(interval=1)\n","log_config = dict(\n","    interval=50,\n","    hooks=[\n","        dict(type='TextLoggerHook', interval=50),\n","        dict(\n","            type='WandbLoggerHook',\n","            interval=100,\n","            init_kwargs=dict(\n","                project='SIA_Project',\n","                entity='jhgsia',\n","                name='head_anchor_ratio_[0.5, 1.0, 1.5, 4.0]'))\n","    ])\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","opencv_num_threads = 0\n","mp_start_method = 'fork'\n","angle_version = 'le90'\n","model = dict(\n","    type='OrientedRCNN',\n","    backbone=dict(\n","        type='ResNet',\n","        depth=50,\n","        num_stages=4,\n","        out_indices=(0, 1, 2, 3),\n","        frozen_stages=1,\n","        norm_cfg=dict(type='BN', requires_grad=True),\n","        norm_eval=True,\n","        style='pytorch',\n","        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n","    neck=dict(\n","        type='FPN',\n","        in_channels=[256, 512, 1024, 2048],\n","        out_channels=256,\n","        num_outs=5),\n","    rpn_head=dict(\n","        type='OrientedRPNHead',\n","        in_channels=256,\n","        feat_channels=256,\n","        version='le90',\n","        anchor_generator=dict(\n","            type='AnchorGenerator',\n","            scales=[8],\n","            ratios=[0.5, 1.0, 1.5, 4.0],\n","            strides=[4, 8, 16, 32, 64]),\n","        bbox_coder=dict(\n","            type='MidpointOffsetCoder',\n","            angle_range='le90',\n","            target_means=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n","            target_stds=[1.0, 1.0, 1.0, 1.0, 0.5, 0.5]),\n","        loss_cls=dict(\n","            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n","        loss_bbox=dict(\n","            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n","    roi_head=dict(\n","        type='OrientedStandardRoIHead',\n","        bbox_roi_extractor=dict(\n","            type='RotatedSingleRoIExtractor',\n","            roi_layer=dict(\n","                type='RoIAlignRotated',\n","                out_size=7,\n","                sample_num=2,\n","                clockwise=True),\n","            out_channels=256,\n","            featmap_strides=[4, 8, 16, 32]),\n","        bbox_head=dict(\n","            type='RotatedShared2FCBBoxHead',\n","            in_channels=256,\n","            fc_out_channels=1024,\n","            roi_feat_size=7,\n","            num_classes=3,\n","            bbox_coder=dict(\n","                type='DeltaXYWHAOBBoxCoder',\n","                angle_range='le90',\n","                norm_factor=None,\n","                edge_swap=True,\n","                proj_xy=True,\n","                target_means=(0.0, 0.0, 0.0, 0.0, 0.0),\n","                target_stds=(0.1, 0.1, 0.2, 0.2, 0.1)),\n","            reg_class_agnostic=True,\n","            loss_cls=dict(\n","                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n","            loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))),\n","    train_cfg=dict(\n","        rpn=dict(\n","            assigner=dict(\n","                type='MaxIoUAssigner',\n","                pos_iou_thr=0.7,\n","                neg_iou_thr=0.3,\n","                min_pos_iou=0.3,\n","                match_low_quality=True,\n","                ignore_iof_thr=-1),\n","            sampler=dict(\n","                type='RandomSampler',\n","                num=256,\n","                pos_fraction=0.5,\n","                neg_pos_ub=-1,\n","                add_gt_as_proposals=False),\n","            allowed_border=0,\n","            pos_weight=-1,\n","            debug=False),\n","        rpn_proposal=dict(\n","            nms_pre=2000,\n","            max_per_img=2000,\n","            nms=dict(type='nms', iou_threshold=0.8),\n","            min_bbox_size=0),\n","        rcnn=dict(\n","            assigner=dict(\n","                type='MaxIoUAssigner',\n","                pos_iou_thr=0.5,\n","                neg_iou_thr=0.5,\n","                min_pos_iou=0.5,\n","                match_low_quality=False,\n","                iou_calculator=dict(type='RBboxOverlaps2D'),\n","                ignore_iof_thr=-1),\n","            sampler=dict(\n","                type='RRandomSampler',\n","                num=512,\n","                pos_fraction=0.25,\n","                neg_pos_ub=-1,\n","                add_gt_as_proposals=True),\n","            pos_weight=-1,\n","            debug=False)),\n","    test_cfg=dict(\n","        rpn=dict(\n","            nms_pre=2000,\n","            max_per_img=2000,\n","            nms=dict(type='nms', iou_threshold=0.8),\n","            min_bbox_size=0),\n","        rcnn=dict(\n","            nms_pre=2000,\n","            min_bbox_size=0,\n","            score_thr=0.05,\n","            nms=dict(iou_thr=0.1),\n","            max_per_img=2000)))\n","work_dir = './work_dirs/oriented_rcnn_r50_fpn_1x_dota_le90'\n","auto_resume = False\n","gpu_ids = range(0, 1)\n","\n","2022-09-26 01:41:48,551 - mmrotate - INFO - Set random seed to 1400836405, deterministic: False\n","/usr/local/lib/python3.7/dist-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n","  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n","2022-09-26 01:41:48,923 - mmrotate - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n","2022-09-26 01:41:48,924 - mmcv - INFO - load model from: torchvision://resnet50\n","2022-09-26 01:41:48,924 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n","2022-09-26 01:41:49,024 - mmcv - WARNING - The model and loaded state dict do not match exactly\n","\n","unexpected key in source state_dict: fc.weight, fc.bias\n","\n","2022-09-26 01:41:49,045 - mmrotate - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n","2022-09-26 01:41:49,071 - mmrotate - INFO - initialize OrientedRPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n","2022-09-26 01:41:49,075 - mmrotate - INFO - initialize RotatedShared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n","2022-09-26 01:41:55,087 - mmrotate - INFO - Start running, host: root@5192798676f5, work_dir: /content/mmrotate/work_dirs/oriented_rcnn_r50_fpn_1x_dota_le90\n","2022-09-26 01:41:55,088 - mmrotate - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n","(VERY_LOW    ) WandbLoggerHook                    \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n","(VERY_LOW    ) WandbLoggerHook                    \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n","(VERY_LOW    ) WandbLoggerHook                    \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n","(VERY_LOW    ) WandbLoggerHook                    \n"," -------------------- \n","before_val_epoch:\n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n","(VERY_LOW    ) WandbLoggerHook                    \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n","(VERY_LOW    ) WandbLoggerHook                    \n"," -------------------- \n","after_run:\n","(VERY_LOW    ) TextLoggerHook                     \n","(VERY_LOW    ) WandbLoggerHook                    \n"," -------------------- \n","2022-09-26 01:41:55,088 - mmrotate - INFO - workflow: [('train', 1)], max: 12 epochs\n","2022-09-26 01:41:55,088 - mmrotate - INFO - Checkpoints will be saved to /content/mmrotate/work_dirs/oriented_rcnn_r50_fpn_1x_dota_le90 by HardDiskBackend.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjhgsia\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/mmrotate/wandb/run-20220926_014155-3anz2wcp\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhead_anchor_ratio_[0.5, 1.0, 1.5, 4.0]\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jhgsia/SIA_Project\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jhgsia/SIA_Project/runs/3anz2wcp\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n","  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n","2022-09-26 01:42:07,385 - mmrotate - INFO - Epoch [1][50/4021]\tlr: 1.993e-03, eta: 3:08:04, time: 0.234, data_time: 0.052, memory: 1429, loss_rpn_cls: 0.4653, loss_rpn_bbox: 0.1669, loss_cls: 0.2008, acc: 96.0293, loss_bbox: 0.0423, loss: 0.8753, grad_norm: 5.3450\n","2022-09-26 01:42:15,940 - mmrotate - INFO - Epoch [1][100/4021]\tlr: 2.327e-03, eta: 2:42:35, time: 0.171, data_time: 0.015, memory: 1429, loss_rpn_cls: 0.2205, loss_rpn_bbox: 0.1654, loss_cls: 0.1838, acc: 94.5391, loss_bbox: 0.1807, loss: 0.7503, grad_norm: 4.9569\n","2022-09-26 01:42:23,731 - mmrotate - INFO - Epoch [1][150/4021]\tlr: 2.660e-03, eta: 2:29:55, time: 0.156, data_time: 0.004, memory: 1429, loss_rpn_cls: 0.1582, loss_rpn_bbox: 0.1233, loss_cls: 0.1760, acc: 94.9785, loss_bbox: 0.2112, loss: 0.6687, grad_norm: 4.6566\n","2022-09-26 01:42:31,536 - mmrotate - INFO - Epoch [1][200/4021]\tlr: 2.993e-03, eta: 2:23:34, time: 0.156, data_time: 0.004, memory: 1507, loss_rpn_cls: 0.1658, loss_rpn_bbox: 0.1999, loss_cls: 0.1687, acc: 94.7207, loss_bbox: 0.2154, loss: 0.7499, grad_norm: 4.4412\n","2022-09-26 01:42:39,262 - mmrotate - INFO - Epoch [1][250/4021]\tlr: 3.327e-03, eta: 2:19:28, time: 0.155, data_time: 0.004, memory: 1507, loss_rpn_cls: 0.1362, loss_rpn_bbox: 0.1330, loss_cls: 0.1799, acc: 93.6699, loss_bbox: 0.2728, loss: 0.7219, grad_norm: 4.4592\n","2022-09-26 01:42:47,058 - mmrotate - INFO - Epoch [1][300/4021]\tlr: 3.660e-03, eta: 2:16:52, time: 0.156, data_time: 0.004, memory: 1507, loss_rpn_cls: 0.1008, loss_rpn_bbox: 0.1203, loss_cls: 0.1917, acc: 93.4160, loss_bbox: 0.2986, loss: 0.7114, grad_norm: 4.5252\n","2022-09-26 01:42:54,889 - mmrotate - INFO - Epoch [1][350/4021]\tlr: 3.993e-03, eta: 2:15:03, time: 0.157, data_time: 0.004, memory: 1507, loss_rpn_cls: 0.0931, loss_rpn_bbox: 0.1084, loss_cls: 0.1615, acc: 93.7012, loss_bbox: 0.2624, loss: 0.6254, grad_norm: 3.7881\n","2022-09-26 01:43:03,239 - mmrotate - INFO - Epoch [1][400/4021]\tlr: 4.327e-03, eta: 2:14:41, time: 0.167, data_time: 0.015, memory: 1529, loss_rpn_cls: 0.0977, loss_rpn_bbox: 0.1545, loss_cls: 0.1753, acc: 93.5527, loss_bbox: 0.3832, loss: 0.8107, grad_norm: 3.6680\n","2022-09-26 01:43:11,397 - mmrotate - INFO - Epoch [1][450/4021]\tlr: 4.660e-03, eta: 2:14:03, time: 0.163, data_time: 0.011, memory: 1529, loss_rpn_cls: 0.1094, loss_rpn_bbox: 0.1329, loss_cls: 0.1721, acc: 94.0059, loss_bbox: 0.3095, loss: 0.7239, grad_norm: 3.8820\n","2022-09-26 01:43:19,243 - mmrotate - INFO - Epoch [1][500/4021]\tlr: 4.993e-03, eta: 2:13:00, time: 0.157, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.0940, loss_rpn_bbox: 0.1342, loss_cls: 0.1620, acc: 93.7949, loss_bbox: 0.3033, loss: 0.6936, grad_norm: 3.8369\n","2022-09-26 01:43:27,075 - mmrotate - INFO - Epoch [1][550/4021]\tlr: 5.000e-03, eta: 2:12:06, time: 0.157, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.1079, loss_rpn_bbox: 0.1370, loss_cls: 0.1655, acc: 93.8203, loss_bbox: 0.3375, loss: 0.7478, grad_norm: 3.5468\n","2022-09-26 01:43:34,957 - mmrotate - INFO - Epoch [1][600/4021]\tlr: 5.000e-03, eta: 2:11:24, time: 0.158, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.0557, loss_rpn_bbox: 0.0808, loss_cls: 0.1345, acc: 94.8730, loss_bbox: 0.3052, loss: 0.5762, grad_norm: 2.8960\n","2022-09-26 01:43:42,814 - mmrotate - INFO - Epoch [1][650/4021]\tlr: 5.000e-03, eta: 2:10:45, time: 0.157, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.0897, loss_rpn_bbox: 0.1128, loss_cls: 0.1428, acc: 94.6562, loss_bbox: 0.2910, loss: 0.6363, grad_norm: 3.1419\n","2022-09-26 01:43:50,684 - mmrotate - INFO - Epoch [1][700/4021]\tlr: 5.000e-03, eta: 2:10:12, time: 0.157, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.0835, loss_rpn_bbox: 0.1034, loss_cls: 0.1520, acc: 94.1719, loss_bbox: 0.3406, loss: 0.6796, grad_norm: 3.5178\n","2022-09-26 01:43:58,498 - mmrotate - INFO - Epoch [1][750/4021]\tlr: 5.000e-03, eta: 2:09:38, time: 0.156, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.0918, loss_rpn_bbox: 0.1347, loss_cls: 0.1427, acc: 94.3066, loss_bbox: 0.3672, loss: 0.7364, grad_norm: 3.4754\n","2022-09-26 01:44:06,301 - mmrotate - INFO - Epoch [1][800/4021]\tlr: 5.000e-03, eta: 2:09:07, time: 0.156, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.0820, loss_rpn_bbox: 0.0844, loss_cls: 0.1555, acc: 94.0254, loss_bbox: 0.2710, loss: 0.5929, grad_norm: 2.9832\n","2022-09-26 01:44:15,195 - mmrotate - INFO - Epoch [1][850/4021]\tlr: 5.000e-03, eta: 2:09:40, time: 0.178, data_time: 0.025, memory: 1529, loss_rpn_cls: 0.0747, loss_rpn_bbox: 0.0706, loss_cls: 0.1561, acc: 94.1406, loss_bbox: 0.3277, loss: 0.6291, grad_norm: 3.2584\n","2022-09-26 01:44:23,018 - mmrotate - INFO - Epoch [1][900/4021]\tlr: 5.000e-03, eta: 2:09:11, time: 0.156, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.0673, loss_rpn_bbox: 0.0832, loss_cls: 0.1428, acc: 94.3652, loss_bbox: 0.2910, loss: 0.5843, grad_norm: 2.8936\n","2022-09-26 01:44:30,786 - mmrotate - INFO - Epoch [1][950/4021]\tlr: 5.000e-03, eta: 2:08:42, time: 0.155, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.0658, loss_rpn_bbox: 0.0898, loss_cls: 0.1247, acc: 95.0996, loss_bbox: 0.2540, loss: 0.5343, grad_norm: 2.7973\n","2022-09-26 01:44:38,807 - mmrotate - INFO - Exp name: oriented_rcnn_r50_fpn_1x_dota_le90.py\n","2022-09-26 01:44:38,807 - mmrotate - INFO - Epoch [1][1000/4021]\tlr: 5.000e-03, eta: 2:08:27, time: 0.160, data_time: 0.007, memory: 1529, loss_rpn_cls: 0.0757, loss_rpn_bbox: 0.0951, loss_cls: 0.1379, acc: 94.9219, loss_bbox: 0.2513, loss: 0.5601, grad_norm: 2.9066\n","2022-09-26 01:44:46,636 - mmrotate - INFO - Epoch [1][1050/4021]\tlr: 5.000e-03, eta: 2:08:05, time: 0.157, data_time: 0.004, memory: 1529, loss_rpn_cls: 0.0575, loss_rpn_bbox: 0.0749, loss_cls: 0.1155, acc: 95.4805, loss_bbox: 0.2341, loss: 0.4820, grad_norm: 2.6966\n","2022-09-26 01:44:54,834 - mmrotate - INFO - Epoch [1][1100/4021]\tlr: 5.000e-03, eta: 2:07:59, time: 0.164, data_time: 0.010, memory: 1529, loss_rpn_cls: 0.0774, loss_rpn_bbox: 0.0901, loss_cls: 0.1331, acc: 95.2637, loss_bbox: 0.2683, loss: 0.5690, grad_norm: 3.0140\n"]}],"source":["!python ./tools/train.py ./configs/oriented_rcnn/oriented_rcnn_r50_fpn_1x_dota_le90.py"]},{"cell_type":"code","source":["from mmdet.apis import inference_detector, show_result_pyplot\n","\n","# 시각화3\n","img = mmcv.imread('/content/mmrotate/data/split_ss_dota/val/images/14.png')\n","model.cfg = cfg\n","result = inference_detector(model, img)\n","show_result_pyplot(model, img, result, score_thr=0.8)"],"metadata":{"id":"Im5zEkUrsjTA","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"error","timestamp":1664156495470,"user_tz":-540,"elapsed":2,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}},"outputId":"cc4eaa18-6e66-4559-d266-3d45f3550dee"},"execution_count":43,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-d1e9139a82fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 시각화3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/mmrotate/data/split_ss_dota/val/images/14.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'mmcv' is not defined"]}]},{"cell_type":"code","source":["from mmdet.apis import inference_detector, show_result_pyplot\n","\n","# 시각화3\n","img = mmcv.imread('/content/mmrotate/data/split_ss_dota/val/images/319.png')\n","model.cfg = cfg\n","result = inference_detector(model, img)\n","show_result_pyplot(model, img, result, score_thr=0.8)"],"metadata":{"id":"4n6hldzjN6ue","executionInfo":{"status":"aborted","timestamp":1664156495471,"user_tz":-540,"elapsed":2,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mmdet.apis import inference_detector, show_result_pyplot\n","\n","# 시각화3\n","img = mmcv.imread('/content/mmrotate/data/split_ss_dota/val/images/379.png')\n","model.cfg = cfg\n","result = inference_detector(model, img)\n","show_result_pyplot(model, img, result, score_thr=0.8)"],"metadata":{"id":"0c1GK758N-O8","executionInfo":{"status":"aborted","timestamp":1664156495471,"user_tz":-540,"elapsed":2,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mmdet.apis import inference_detector, show_result_pyplot\n","\n","# 시각화3\n","img = mmcv.imread('/content/mmrotate/data/split_ss_dota/val/images/467.png')\n","model.cfg = cfg\n","result = inference_detector(model, img)\n","show_result_pyplot(model, img, result, score_thr=0.8)"],"metadata":{"id":"quwGtISmOGjE","executionInfo":{"status":"aborted","timestamp":1664156495471,"user_tz":-540,"elapsed":2,"user":{"displayName":"윤혜연","userId":"13048533309979940862"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gpsPvL_UbRdR"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}